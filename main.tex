\documentclass[conference]{IEEEtran}
% Add the compsoc option for Computer Society conferences.
%
% IfIEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}

\pagestyle{plain}

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algpseudocode} % changed from &&&& 
\usepackage{algorithm} % changed from &&&& 
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{url} % to enable usage of long URLs ion the bib (otherwise they escape the line)
\usepackage{csvsimple}
\usepackage{tabularx}
\usepackage{xfrac}

\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    allcolors=.,
    urlcolor=blue,
}

\title{Hardware Transmitter Fingerprinting in the ARINC 429 Avionic Bus}
%\author{Avishai Wool, Nimrod Gilboa Markevich}
\author{Anonymous}

\begin{document}

\maketitle

\begin{abstract}
    bla
    
    e.g., 
    
    i.e.,
    
    etc.,
    
    et al.\ said
    
\end{abstract}


\section{Introduction}
  \color{gray}
  We propose an intruder detection algorithm for the ARINC 429 data bus, that bases its decisions solely based on the analog properties of the transmitter, receiver(s) and bus topology.
  \color{black}

\subsection{Motivation}
  \color{gray}
  Advantage 1: ...Of course, the attacker is aware of the possibility of a cyber defence systems monitoring the communication on the bus. As a countermeasure, they will attempt to mask the offensive data as data naturally occurring in the system. This type of operation is meant to make it hard for defence systems to detect intruders solely based on the digital data. Advantage 2: (Is it true to say, that other algorithms require a sequence of words, while ours can make a decision based on a single word? Maybe other systems can do that too, or maybe our system should use more than one word for robustness?)
  \color{black}

\subsection{Related Work}
  \cite{uluagac2013passive} - wired fingerprinting based on packet inter-arrival time, wired side of wireless network components (routers)
  \cite{pimentel2014review} - A review of novelty detection
  \cite{jaynes2016automating} - Vehicle ECU. features are mostly data payload, but they suggest using delays
  \cite{cho2016fingerprinting} - fingerprinting ECUs. Based on clocks (offset, frequency, skew). Also looks like a good intro. this paper has 130+ quotes.
  \cite{choi2018identifying} - ECUs. features very similar to Scission, without segmentation. they extract from labels. even use EXID for more bits.
  
  DTW?

\color{gray}
hardware fingerprinting ethernet

\cite{kneib2018scission}
\color{black}


\subsection{Contributions}

\section{Preliminaries}
% stuff we didn't invent or discover but the reader needs to know
\subsection{The ARINC 429 Standard}
  ARINC Specification 429 \cite{}, also named ``Mark 33 Digital Transfer System (DITS)'', is a standard of the avionics industry. It defines a protocol for the communication between avionics system elements over a local area network. First published in 1977 by Aeronautical Radio, Inc., it has since become one of the most widely used data bus protocols in commercial aircrafts \cite{}. The protocol encompasses different layers: from the physical requirements, through the electronic characteristics of the signal, data format and ending with a file transfer technique.

  We continue with a short description of those parts of the specifications, which are relevant to this paper. Data is transmitted over a single twisted and shielded pair of wires. The cable shield is be grounded on both ends. The lines are named Line A and Line B. Differential signaling is used, meaning that the signal is the voltage difference from Line A to Line B, rather than the difference from one wire to ground. Bipolar return-to-zero modulation is used as a line protocol. A BRTZ is a tri-level state modulation. Using the same terms as in the specification, we refer to the three voltage levels as ``HI'', ``LOW'' and ``NULL''. A binary 1 is encoded as a positive voltage pulse ``HI'', and a binary 0 is encoded as a negative voltage pulse ``LOW''. In between transmissions, the voltage drops to 0V, ``NULL''. Every ``HI'' and every ''LOW'' are preceded and are followed by a ``NULL'', even if the bits are transmitted consecutively. The differential output voltage from line A to line B is $10V \pm 1$ in ``HI'' mode, $0 \pm 0.5$ in ``NULL'' mode and $-10V \pm 1$ in ``LO'' mode.  Figure \ref{fig:word_example} shows a recording of a transmission on an ARINC 429 data bus.
  
  Data is transmitted in words that are 32-bit long. The bits are transmitted in the following order, from first to last: 8, 7, ..., 2, 1, 9, 10, ..., 32. This order is a legacy from older systems. In this paper, word are interpreted as though an MSB first transmission order is in place.
  
  Data is transmitted one-way from one transmitter to up to 20 receivers over designated ports. Only one transmitter is allowed on the bus - a separate bus is required for each transmitter.  
   
  The protocol allows a choice of one of two bit rates. Slow, within the range of 12.0 to 14.5 Kbits/sec, and fast, 100 Kbits/sec. The bit rate on a bus is fixed and maintained within \%1. The signal is self-clocking.
  
  The specification does not address the issue of authentication. \textcolor{gray}{(expand)}
   
  MIL-STD-1553 \cite{} is the military bus standard alternative of ARINC 429.
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Traces/word.png}
    \caption{ARINC 429 bus showing the voltage difference between twisted pair}
    \label{fig:word_example}
  \end{figure}
  
  \textcolor{gray}{(Should we address lack of authentication here (in addition to mentioning it in the motivation section)?)}

\subsection{The Adversary Model}
  Out method is designed to guard against technician attacks. This type of attack involves an adversary that has physical access to the system. Such an adversary is able to replace a legitimate transmitter with a malicious one. During an initial dormant phase of the attack, the new device imitates the behavior of the legitimate transmitter, transmitting data exactly as requested, in order to remain hidden. Only at a later time, the attack moves on to its active phase. During this phase the malicious transmitter sends out messages which disrupt the work of the system, and in extreme cases causes irreversible damage to the electronic or physical components. \textcolor{red}{back to sleep etc.,}
  
  % DELETE THIS PARAGRAPH?
  % An attacker may or may not posses knowledge of the bus topology - i.e., number of receivers, distances, and models of connected devices. The attacker will try their best to mimic the characteristics of the original transmitter. In the most case for the defenders, the attacker will use a transmitter which is identical (same manufacturer and model) to the compromised transmitter. (True statement? It is theoretically possible to use a massive signal generator, or maybe a dedicated device that can adjust itself to the real transmitter).

  The attacker may have prior knowledge of the hardware and topology of the attacked system. The reverse is not true. As defenders, we have no prior knowledge, what the attackers hardware might be. However, we do assume that the adversary will use a commercial off-the-shelf transmitter. Therefore, we used commercial transmitters in our tests.

  The monitoring system we propose has to be fitted to the bus it is guarding. During a training period \textcolor{gray}{(session/multiple sessions. We don't want to commit to a length.)} it samples the bus and learns the transmitter's characteristics. We assume that during this time only legitimate devices are present on the bus. We further assume that access to the monitoring system is restricted, so that only authorized personnel are able to trigger the training mechanism. This restriction is in place in order to prevent an attacker from retraining the monitoring system after switching the legitimate transmitter for the malicious one. 

\subsection{Adding another transmitter - fails}
  It is important to remember that the ARINC 429 bus is designed to allow exactly one transmitter. Connecting two transmitters to the same bus violates the protocol. The adversary needs to make sure that the legitimate transmitter is disconnected, before connecting the rogue attacking transmitter. Otherwise, there is a risk that data will fail to be delivered. In fact, when we naively connected two transmitters to the same bus, the peak to peak voltage dropped by half, and the legitimate communication on the bus failed. While we don't assert that this will always be the case, it serves as a cautionary anecdote for the attackers.

\section{Signal Segmentation}
  Our method aims to rely solely on the physical characteristics of the hardware, and to be completely agnostic to the transmitted data. In order to achieve this goal, each word is segmented to 127 segments of 10 different types.
  
  The segmentation is performed in the following manner. A segment starts where the voltage level of the signal rises above / falls below a certain threshold, and ends where it falls below / rises above another threshold. Four different levels of thresholds are employed in order to produce a stabling hysteresis effect. We notate them as follows, and use them and their negative to define segment boundaries:
  
  \begin{align*}
    V_{l_1} = 2.0V \\
    V_{l_2} = 2.8V \\
    V_{h_1} = 8.0V \\
    V_{h_2} = 7.2V 
  \end{align*}
  
  Table \ref{tab:SegmentationLevels} shows the voltage levels used for each segment type. Figure \ref{fig:SegmentationTrace} shows an example of word segmentation. \textcolor{gray}{(I'll change the trace. The current figure is confusing).}
  
  \begin{table}
    \caption{Voltage Thresholds per Segment Type}
    \label{tab:SegmentationLevels}
    \centering
    \begin{tabular}{|c c c|} 
      \hline
      Segment & Starting Threshold & Ending Threshold \\ [0.5ex] 
      \hline\hline
      LO & falls below $-V_{h_1}$ & rises above $-V_{h_2}$ \\
      \hline
      HI & rises above $V_{h_1}$ & falls below $V_{h_2}$ \\
      \hline
      NULL, HI to HI & falls below $V_{l_1}$ & rises above $V_{l_2}$ \\
      \hline
      NULL, HI to LO & falls below $V_{l_1}$ & falls below $-V_{l_2}$ \\
      \hline
      NULL, LO to LO & rises above $-V_{l_1}$ & falls below $-V_{l_2}$ \\
      \hline
      NULL, LO to HI & rises above $-V_{l_1}$ & rises above $V_{l_2}$ \\
      \hline
      Up from LO & rises above $-V_{h_2}$ & rises above $-V_{l_1}$ \\
      \hline
      Up from NULL & rises above $V_{l_2}$ & rises above $V_{h_1}$ \\
      \hline
      Down from HI & falls below $V_{h_2}$ & falls below $V_{l_1}$ \\
      \hline
      Down from NULL & falls below $-V_{l_2}$ & falls below $-V_{h_1}$ \\
      \hline
    \end{tabular}
  \end{table}
  
  Note that there are only 127 segments, not 128, because the last bit is followed by a long NULL that lasts until the next word. We ignore this last segment, because it is unique.
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Traces/segmentation.png}
    \caption{A Segmentation Example of the bits 001011}
    \label{fig:SegmentationTrace}
  \end{figure}
  
  \color{gray}
  why - data agnostic
  quarter-bits; how
  show graph of segmented signal (?)
  characteristics: ascent, over/under-shoot, return to zero and go down/up,
  etc...

  sampling rate + subsampling
  \color{black}
  
\section{The Hardware Fingerprinting Approach}
  An intruder detection system which draws its information exclusively from the digital content of the transmitted messages will be unable to detect the switch during the dormant phases. Only during an active phase of the attack is the transmitted data distinguishable from that of a legitimate transmission. We propose an intruder detection system that utilizes information from the analog domain. On the electronic level, the two transmitters differ even on during dormant phases. The malicious hardware can be flashed out as soon as it begins signalling \textcolor{gray}{(usually, before takeoff, all the systems are checked. during this pre-flight operations the switch will be detected. the attacker will not have the opportunity to activate during flight, thus preventing life endangering situations. saves the need to make mid-flight decisions on how to deal with intruders.)}
  
  In the following section we describe the key aspects of our algorithm.

\subsection{Overview} \label{Overview}
  When a new word is captured and tested for anomalies, we process it in several stages. This section provides an overview of these steps. In later sections the method is explained in greater detail.
  
  \begin{enumerate}
    \item \textbf{[Acquisition]}
          We sample both lines of the bus at a sampling rate that is 50 times higher than what is needed, in order to extract just the bits. The differential signal is received from subtracting the samples of line B from the samples of line A.
    \item \textbf{[Segmentation]}
          First, the word is broken done into 127 small segments of 10 different types, based on voltage levels. The purpose of the segmentation is to diffuse the effect of the transmitted data, the content of the word, on the final decision of the anomaly detector.
    \item \textbf{[Feature Extraction]}
          Multiple features are extracted from each segment. 
    \item \textbf{[Anomaly Detection Per Segment]}
          The features from each segment are fed into a trained anomaly detector. Each segment is marked as either ``normal'' or ``anomaly''.
    \item \textbf{[Voting]}
          A word is declared as an anomaly, if the number of ``anomaly'' segments accedes a predetermined threshold.
  \end{enumerate}
  
\subsection{The Data Corpus}
  \textcolor{gray}{(equipment measured, sampling layout, sampling scope \& rate, transmitted data, number of traces, photo of connection board)}
  
  To the best of our knowledge, there is no publicly available data corpus that contains high rate samples of ARINC 429 protocol. We built our own data set, with the kind assistance of \textit{Astronautics C.A. LTD.} \cite{}.
  
  We sampled two types of devices: a M4K429RTx test equipment from \textit{Excalibur Systems} \cite{}. The Excalibur equipment hosts two transmitters, on two \textcolor{gray}{(identical?)} boards. We label them E1 and E2. The other device is a HI-8597PSIF chip on HI-3220PQ Evaluation Board, manufactured by \textit{Holt Integrated Circuits INC.} \cite{}. We used one of two boards. Each board contains 4 chips. Each chip has 1 transmitter and 2 receivers. We label the transmitters H{x}{y}, where x is the board number, 1 or 2, and y is the transmitter number from 1 to 4. The receivers are labeled the same way. The Excaliber or one of the Holt boards communicated with a proprietary device manufactured by Astronautics. \textcolor{gray}{(What are we allowed to say about the Pilatus?)}. This device was not sampled as a transmitter. We labeld the devices P1 and P2.
  
  For sampling we used a Keysight DSO9254A scope. All signals were sampled at 50Msa/s at a scope bandwidth of 25MHz. The probes are 500MHz, 10M\(\Omega\), 11pF. Each line was sampled individually. In some experiments further downsampling by a factor of 10, to 5 MSa/s was performed digitally on the differential signal, using a 30 point FIR filter with Hamming window.
  
  The transmitters and receivers were connected through a board that exposes the wires, that we fabricated for this purpose (see Figure \ref{fig:SetupImage}).
  
  \begin{figure}[t]
    \centering
    %Use 1 for the two columns
    \includegraphics[width=1.0\linewidth, angle=0]{Images/setup_3}
    \caption{Holt Evaluation Board sampled}
    \label{fig:SetupImage}
  \end{figure}
  
  All devices transmitted the same data. 6 values of words were transmitted. Interpreting the words with MSB first transmission order, the values are: \texttt{0x00000000}, \texttt{0xFFFFFFFF}, \texttt{0x55555555}, \texttt{0xAAAAAAAA}, \texttt{0x5A5A5A5A}, \texttt{0xA5A5A5A5}. Transmitting the same data on all devices eliminates the possibility, that instead of learning the analog features, our transmitter unintentionally will learn the encoded data.
  
  In addition to recording transmitter-receiver pairs, we recorded E1 and E2 transmitting to P1 and P2 respectfully, with different Holt devices attached as additional transmitters. Table \ref{tab:RecordingsSummery} shows the different combinations of transmitter-receiver in our data set, and the number of words recorded for each combination.
  
  \begin{table}
    \caption{Distribution of recorded words in data set}
    \label{tab:RecordingsSummery}
    \centering
    \begin{tabular}{|c c c|} 
      \hline
      Transmitter & Receiver & \#Words \\ [0.5ex] 
      \hline\hline
      E1 & P1 & 4920 \\ % There are actually 9840, but I use half to keep a balanced data set.
      \hline
      E1 & P1, H10 & 4920 \\
      \hline
      E1 & P1, H12 & 4920 \\
      \hline
      E1 & P1, H20 & 4920 \\
      \hline
      E1 & P1, H22 & 4920 \\
      \hline
      H10 & P1 & 4920 \\
      \hline
      H11 & P1 & 4920 \\
      \hline
      H12 & P1 & 4920 \\
      \hline
      H13 & P1 & 4920 \\
      \hline
      H20 & P1 & 4920 \\
      \hline
      H21 & P1 & 4920 \\
      \hline
      H22 & P1 & 4920 \\
      \hline
      H23 & P1 & 4920 \\
      \hline
      E2 & P2 & 4920 \\ % There are actually 9840, but I use half to keep a balanced data set.
      \hline
      E2 & P2, H10 & 4920 \\
      \hline
      E2 & P2, H12 & 4920 \\
      \hline
      E2 & P2, H20 & 4920 \\
      \hline
      E2 & P2, H22 & 4920 \\
      \hline
      H10 & P2 & 4920 \\
      \hline
      H11 & P2 & 4920 \\
      \hline
      H12 & P2 & 4920 \\
      \hline
      H13 & P2 & 4920 \\
      \hline
      H20 & P2 & 4920 \\
      \hline
      H21 & P2 & 4920 \\
      \hline
      H22 & P2 & 4920 \\
      \hline
      H23 & P2 & 4920 \\
      \hline
    \end{tabular}
  \end{table}
  
\subsection{Novelty Detection per Segment}
  As mentioned in the overview [\ref{Overview}], after segmentation and feature  extraction, the next step in our algorithm is to perform per segment anomaly  detection. There are several types of segments, as detailed in Table \ref{tab:RecordingsSummery}. Because the segments are very different from each other \textcolor{gray}{(elaborate: in what respect?)}, we opted for training a different each type of segment we train a different novelty detector.
  \textcolor{gray}{(Maybe segmentation needs to be explained before this section?)}
  
  There are many outlier and novelty detection algorithms available in the literature. K-Nearest Neighbors \cite{hautamaki2004outlier}, Mixture Models \cite{}, One-Class SVM \cite{}, Isolation Forest \cite{liu2008isolation}. An extensive review of various algorithms is presented in \cite{pimentel2014review}.
  
  For the novelty detection task, we chose to work with the Local Outlier Factor (LOF) by Breunig et al.\ \cite{breunig2000lof}. LOF has shown to work better then other algorithms for the task of network intrusion detection\cite{lazarevic2003comparative} \textcolor{gray}{although on traffic, not on analog signals, and in 2003}. This fact, together with the available scikit-learn \cite{scikit-learn} python implementation, made it an appealing choice. Of course, there may be other algorithms that will outperform LOF for this domain. Comparing different anomaly detection algorithms is beyond the scope of this paper.
  
  LOF is a density based outlier detection algorithm. According to the LOF algorithm, an outlier is defined as a data point (sample), whose local density is greater than the average of local densities of its neighbors by a large enough margin. A local density of a data point is the inverse of the average distance of the point from its neighbors.
  
  There are several hyper-parameters for the LOF algorithm. For the number of neighbors examined when calculating the LOF, we used 20. We used the Euclidean metric for the distance measure. The threshold on the local outlier factor that defines an anomaly is automatically set so 10\% of samples in the \textbf{training set} are outliers. These are default parameters provided by implementation.
  
  A separate novelty detector is constructed for each type of segments.
  In this stage, each segment is fed individually into its appropriate LOF novelty detector. The LOF outputs its suggestion regarding the source of the segment, either`legitimate' or `intruder'.
  
\subsection{Word-Based Anomaly Detection}
  We gather all the suggestions made by the different LOF detectors for all segments of the same word. The number of segments that have been identified as legitimate is subjected to a threshold. If it is greater than that threshold, the word is predicted to be legitimate, otherwise, it is flagged as an anomaly.
  
%%%%inline formula $\sum_{i=0}^n x_i $

%%%displayed formula
%%%\[
%%%\sum_{i=0}^n x_i
%%%\]

%%%method 2: half-bits; how

%%%%%%%%%%%%%%%%%
\section{Feature Selection}

  \color{gray}
  advantages of feature selection (model size reduction, speed, accuracy?)
  \color{black}


\subsubsection{Scission Feature}

  \cite{kneib2018scission}

\subsubsection{domain-specific features}
  potential features
  \begin{itemize}
    \item ascent rate
    \item maximum and minimum in plateau
    \item ...
  \end{itemize}
 
 \subsection{The Benjamini Hochberg method}
 
 \cite{benjamini1995controlling}
 
  labeled data
 
  results: top X features  (bar chart)

%%%%%%%%%%%%%%%%%%
\section{Performance Evaluation}

\subsection{Methodology}
  \textcolor{gray}{The main metric we use for evaluation is EER. It is obtained in the following way...}
  
  In order to evaluate the performance of our algorithm, we performed a series of \textcolor{gray}{experiments (detection attempts)}. In each \textcolor{gray}{experiment} we designate one of the our transmitters as the legitimate device to be guarded. In case the transmitter is an Excalibur (e1 or e2), all the other devices are in the role of attackers. In case the transmitter is a holt (h10, ..., h13, h20, ..., h23), all the other Holt devices are in the role of attackers (the Excaliburs are not used in this case). We select one of the two receivers (p1 or p2). We run all the stages of the algorithm with the a set of hyper-parameters to be evaluate (feature set, . We repeat for all possible values of voting thresholds (0 - the number of segments, 127).
  
  We calculate the false-negative-rate and the false-positive-rate (FNR \& FPR respectively) as a function of the threshold. We then find the equal error rate (EER), the rate at which the FNR equals the FPR. The EER is the metric we use for comparing different hyper-parameters.
  For selected cases we plot the FNR and FPR, or the roc curve (TPR vs. FPR), as a visual \textcolor{gray}{demonstration/qualitative evaluation}.
  
  \textcolor{gray}{(something about the training set only containing recordings from the legitimate device.)}
  \textcolor{gray}{e1 only transmits to p1, and e2 to p2, because of limitations}
  \textcolor{gray}{positive is legitimate, negative is malicious}
  In all cases we used a train-test split of 60\%-40\%.
  
\subsection{Identifying a Rogue Transmitter}
  The results of the intruder detection tests described in the previous section are summed up in the form of a box plot in Figure \ref{fig:rogue_transmitter_results}. \textcolor{gray}{(the following is an explanation of a box plot. unnecessary?)} The horizontal line in the middle of the box and the number written next to it indicate the median. The lower and top boundaries of the box indicate the 1st and 3rd quartiles respectively. The horizontal lines outside of the box (the whiskers) are placed on the minimum and maximum values. On top of the box plot, we plotted the individual points, that make up the box plot.
  We display the y axis in false alarms rate (FAR). This gives a more concrete sense to the number. The FAR calculated by multiplying the EER by the maximum message rate. The false alarm rate is the inverse of mean time between failures.
  
  \[FAR = \frac{1}{MTBF} = EER \cdot \frac{100 \sfrac{kbits}{sec}}{32bits}\]
  
  Note that since the FAR is linear in the FNR, and thus in the EER, we can discuss the bar graph as though it displays EER when giving a qualitative analysis.
  
  The results are displayed by feature set. We can observe that intruder detection yields the best results in term of EER when operating in the time domain, without extracting features. Both the median and the spread of the values is low. The EER values for the Scission data set are slightly more spread out, and the median is greater. The poly and the domain specific data sets continue in this trend. It is interesting to note, that even though the domain specific data set performs poorly when guarding some transmitters, for others it achieves an EER of 0.
  
  The data points are color coded by device type. We see that in all feature sets, the Excalibur devices achieve an EER of 0. This might be due to the fact in our experiments, only Holts are used as simulated attackers. When an Excalibur is designated as the legitimate device, the algorithm has to differentiate between two different types of devices. In contrast, when a Holt is the legitimate device, the algorithm has to differentiate between transmitters that are much more similar, either different ports of the same chip (h10 vs. h11), different instances of the same chip (h10 vs. h12, h13) or different instances of the same board model (h10 vs. h2x).
  
  We also calculated the area under the roc curve (AUC) for each measurement. For all features sets excluding domain specific, the AUC ranges from 1.0 down to 0.987. For the domain specific feature set the AUC ranges from 1.0 down to 0.879. \textcolor{gray}{(I'm not sure what else to say about this.)}
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/far_feature_sets_w_domain_w_median.png}
    \caption{identifying a rogue transmitter}
    \label{fig:rogue_transmitter_results}
  \end{figure}
  
  Before discussing Figure \ref{fig:rogue_transmitter_results} as a whole, we will examine two experiments in order to get a better feel for the meaning of each test. Figure \ref{fig:detection_easy_example} show the FNR and the FPR as a function of the threshold value for the e1 as a guarded device, with p1 as a receiver. The Scission set is used. For comparison, Figure \ref{fig:detection_difficult_example} is a representation h21 as a guarded transmitter and p1 as a receiver. It is apparent that this is a more challenging case. In Figure \ref{fig:detection_easy_example}, the FNR and the FPR do not intersect. There is a wide range of thresholds, for which both and FNR of 0 and an FPR of can be achieved simultaneously. In contrast, in \ref{fig:detection_difficult_example} there is only a narrow range of thresholds for which both error rates are small, and the EER is greater than zero.
  
  In an attempt to understand where the difference is coming from, we plot the TPR and the FPR for each type of segment individually, before the voting stage. The graphs are shown in Figure \ref{fig:segments_easy_example} \& in Figure \ref{fig:segments_difficult_example}. We see that the errors are not equally divided among all segment types.
  \textcolor{red}{YOU ARE HERE. explain that the tpr and fnr here are different, because decision is per segment, not per word, and there is no thresholding because of that.}

  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/scission_e1_p1_fnr_fpr.png}
    \caption{TPR and FPR for e1 as guarded as a function of the threshold}
    \label{fig:detection_easy_example}
  \end{figure}
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/scission_h21_p1_fnr_fpr.png}
    \caption{TPR and FPR for h21 as guarded as a function of the threshold}
    \label{fig:detection_difficult_example}
  \end{figure}
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/segments_tpr_tnr_e1_p1.png}
    \caption{Per segment TPR and FPR for e1 as guarded}
    \label{fig:segments_easy_example}
  \end{figure}
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/segments_tpr_tnr_h21_p1.png}
    \caption{Per segment TPR and FPR for h21 as guarded}
    \label{fig:segments_difficult_example}
  \end{figure}
  
  \color{gray}
    graphs of:

    port-to-port sensitivity

    Excalibur as guarded
 
    Holt as guarded
   \color{black}
 
\subsection{Feature-Selection Revisited}

\subsection{Are we sensitive to the transmitter or receiver}
  In this set of experiments we replace the receiver instead of the transmitter. The results are shown in Figure \ref{fig:receiver_results}.
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/far_feature_sets_receiver_w_domain_w_median.png}
    \caption{identifying a rogue transmitter}
    \label{fig:receiver_results}
  \end{figure}
  
\subsection{Adding another receiver}
  In this set of experiments only the Excaliburs are transmitting. One Excalibur transmitts data. This is the guarded transmission. We then add one Holt receiver. We check wether the two states can be told apart.
  
  The results are shown in Figure \ref{fig:load_results}. \textcolor{gray}{I'm not sure we should include this results in our paper, except maybe to show it doesn't work? The mead EER for time feature set is 0.38, and for domain specific it's 0.49 == random.}
  
  \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth, angle=0]{Graphs/far_feature_sets_load_w_domain_w_median.png}
    \caption{identifying a rogue transmitter}
    \label{fig:load_results}
  \end{figure}
  

\subsection{Sensitivity to message content in data set}

\section{Conclusions}

\bibliographystyle{IEEEtranS}
\bibliography{biblio} 

\end{document}